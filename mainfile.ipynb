from google.colab import drive
drive.mount('/content/gdrive')
#Cell 01
# Basic packages
!pip install impyute
import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from scipy import stats; from scipy.stats import zscore, norm, randint
import matplotlib.style as style; style.use('fivethirtyeight')
import plotly.express as px
%matplotlib inline

# Impute and Encode
from sklearn.preprocessing import LabelEncoder
from impyute.imputation.cs import mice


# Modelling - LR, KNN, NB, Metrics
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier, VotingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.dummy import DummyClassifier
from sklearn.metrics import make_scorer

# Oversampling
from imblearn.over_sampling import SMOTE

# Suppress warnings
import warnings; warnings.filterwarnings('ignore')

# Visualize Tree
from sklearn.tree import export_graphviz
from IPython.display import Image
from os import system

# Display settings
pd.options.display.max_rows = 10000
pd.options.display.max_columns = 10000

random_state = 42
np.random.seed(random_state)
#Cell 02
# Reading the data as dataframe and print the first five rows
bank = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/03_Ensemble Techniques/bank-full.csv')
bank.head()
#Cell 03
# Get info of the dataframe columns
bank.info()
#Cell 04
bank.describe(include = 'all').T
#Cell 05
columns = bank.loc[:, bank.dtypes == 'object'].columns.tolist()
for cols in columns:
    print(f'Unique values for {cols} is \n{bank[cols].unique()}\n')
#Cell 06
display(bank['Target'].value_counts(), bank['Target'].value_counts(normalize = True)*100)
#Cell 07
# Replace values in some of the categorical columns
replace_values = {'education': {'unknown': -1, 'primary': 1, 'secondary': 2, 'tertiary': 3}, 'Target': {'no': 0, 'yes': 1},
                  'default': {'no': 0, 'yes': 1}, 'housing': {'no': 0, 'yes': 1}, 'loan': {'no': 0, 'yes': 1},
                  'month': {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
                            'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}}

bank = bank.replace(replace_values)
#Cell 08
# Convert columns to categorical types
columns.extend(['day'])
for cols in columns:
    bank[cols] = bank[cols].astype('category')
#Cell 09
# Functions that will help us with EDA(Exploratory Data Analysis) plot
def odp_plots(df, col):
    f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 7.2))

    # Boxplot to check outliers
    sns.boxplot(x = col, data = df, ax = ax1, orient = 'v', color = 'darkslategrey')

    # Distribution plot with outliers
    sns.distplot(df[col], ax = ax2, color = 'teal', fit = norm).set_title(f'Distribution of {col} with outliers')

    # Removing outliers, but in a new dataframe
    upperbound, lowerbound = np.percentile(df[col], [1, 99])
    y = pd.DataFrame(np.clip(df[col], upperbound, lowerbound))

    # Distribution plot without outliers
    sns.distplot(y[col], ax = ax3, color = 'tab:orange', fit = norm).set_title(f'Distribution of {col} without outliers')

    kwargs = {'fontsize':14, 'color':'black'}
    ax1.set_title(col + ' Boxplot Analysis', **kwargs)
    ax1.set_xlabel('Box', **kwargs)
    ax1.set_ylabel(col + ' Values', **kwargs)

    return plt.show()

def target_plot(df, col, target = 'Target'):
    fig = plt.figure(figsize = (15, 7.2))
    # Distribution for 'Target' -- didn't subscribed, considering outliers
    ax = fig.add_subplot(121)
    sns.distplot(df[(df[target] == 0)][col], color = 'c',
                 ax = ax).set_title(f'{col.capitalize()} for Term Desposit - Didn\'t subscribed')

    # Distribution for 'Target' -- Subscribed, considering outliers
    ax= fig.add_subplot(122)
    sns.distplot(df[(df[target] == 1)][col], color = 'b',
             ax = ax).set_title(f'{col.capitalize()} for Term Desposit - Subscribed')
    return plt.show()

def target_count(df, col1, col2):
    fig = plt.figure(figsize = (15, 7.2))
    ax = fig.add_subplot(121)
    sns.countplot(x = col1, data = df, palette = ['tab:blue', 'tab:cyan'], ax = ax, orient = 'v',
                  hue = 'Target').set_title(col1.capitalize() +' count plot by Target',
                                                                      fontsize = 13)
    plt.legend(labels = ['Didn\'t Subcribed', 'Subcribed'])
    plt.xticks(rotation = 90)

    ax = fig.add_subplot(122)
    sns.countplot(x = col2, data = df, palette = ['tab:blue', 'tab:cyan'], ax = ax, orient = 'v',
                  hue = 'Target').set_title(col2.capitalize() +' coount plot by Target',
                                                                      fontsize = 13)
    plt.legend(labels = ['Didn\'t Subcribed', 'Subcribed'])
    plt.xticks(rotation = 90)
    return plt.show()
#Cell 10
# Subscribe and didn't subscribe for categorical columns
target_count(bank, 'job', 'marital')
target_count(bank, 'education', 'default')
target_count(bank, 'housing', 'loan')
target_count(bank, 'contact', 'day')
target_count(bank, 'month', 'poutcome')
#Cell 11
# Outlier, distribution for 'age' column
Q3 = bank['age'].quantile(0.75)
Q1 = bank['age'].quantile(0.25)
IQR = Q3 - Q1

print('Age column', '--'*55)
display(bank.loc[(bank['age'] < (Q1 - 1.5 * IQR)) | (bank['age'] > (Q3 + 1.5 * IQR))].head())

odp_plots(bank, 'age')

# Distribution of 'age' by 'Target'
target_plot(bank, 'age')
#Cell 12
# Outlier, distribution for 'balance' column
Q3 = bank['balance'].quantile(0.75)
Q1 = bank['balance'].quantile(0.25)
IQR = Q3 - Q1
print('Balance column', '--'*55)
display(bank.loc[(bank['balance'] < (Q1 - 1.5 * IQR)) | (bank['balance'] > (Q3 + 1.5 * IQR))].head())

odp_plots(bank, 'balance')

# Distribution of 'balance' by 'Target'
target_plot(bank, 'balance')
#Cell 13
# Outlier, distribution for 'duration' column
Q3 = bank['duration'].quantile(0.75)
Q1 = bank['duration'].quantile(0.25)
IQR = Q3 - Q1

print('Duration column', '--'*54)
display(bank.loc[(bank['duration'] < (Q1 - 1.5 * IQR)) | (bank['duration'] > (Q3 + 1.5 * IQR))].head())

odp_plots(bank, 'duration')

# Distribution of 'duration' by 'Target'
target_plot(bank, 'duration')
#Cell 14
# Outlier, distribution for 'campaign' column
Q3 = bank['campaign'].quantile(0.75)
Q1 = bank['campaign'].quantile(0.25)
IQR = Q3 - Q1

print('Campaign column', '--'*54)
display(bank.loc[(bank['campaign'] < (Q1 - 1.5 * IQR)) | (bank['campaign'] > (Q3 + 1.5 * IQR))].head())

odp_plots(bank, 'campaign')

# Distribution of 'campaign' by 'Target'
target_plot(bank, 'campaign')
#Cell 15
# Outlier, distribution for 'pdays' column
Q3 = bank['pdays'].quantile(0.75)
Q1 = bank['pdays'].quantile(0.25)
IQR = Q3 - Q1

print('Pdays column', '--'*55)
display(bank.loc[(bank['pdays'] < (Q1 - 1.5 * IQR)) | (bank['pdays'] > (Q3 + 1.5 * IQR))].head())

# Check outlier in 'pdays', not considering -1
pdays = bank.loc[bank['pdays'] > 0, ['pdays', 'Target']]
pdays = pd.DataFrame(pdays, columns = ['pdays', 'Target'])
odp_plots(pdays, 'pdays')

# Distribution of 'pdays' by 'Target', not considering -1
target_plot(pdays, 'pdays')
#Cell 16
# Outlier, distribution and probability plot for 'previous' column
Q3 = bank['previous'].quantile(0.75)
Q1 = bank['previous'].quantile(0.25)
IQR = Q3 - Q1

print('Previous column', '--'*54)
display(bank.loc[(bank['previous'] < (Q1 - 1.5 * IQR)) | (bank['previous'] > (Q3 + 1.5 * IQR))].head())

odp_plots(bank, 'previous')

# Distribution of 'previous' by 'Target'
target_plot(bank, 'previous')
#Cell 17
print('Categorical Columns: \n{}'.format(list(bank.select_dtypes('category').columns)))
print('\nNumerical Columns: \n{}'.format(list(bank.select_dtypes(exclude = 'category').columns)))
#Cell 18
# Removing outliers with upper and lower percentile values being 99 and 1, respectively
bank_nulls = bank.copy(deep = True)
columns = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']

for col in columns:
    upper_lim = np.percentile(bank_nulls[col].values, 99)
    lower_lim = np.percentile(bank_nulls[col].values, 1)
    bank_nulls.loc[(bank_nulls[col] > upper_lim), col] = np.nan
    bank_nulls.loc[(bank_nulls[col] < lower_lim), col] = np.nan

print('Column for which outliers where removed with upper and lower percentile values: \n', columns)
#Cell 19
# pd.get_dummies
cols_to_transform = ['job', 'marital', 'contact', 'poutcome']
bank_nulls = pd.get_dummies(bank_nulls, columns = cols_to_transform) #, drop_first = True)

print('Got dummies for \n', cols_to_transform)
bank_nulls.info()
#Cell 20
# Convert 'astype' of categorical columns to integer for getting it ready for MICE
columns = ['education', 'default', 'housing', 'loan', 'day', 'month', 'Target']
for col in columns:
    bank_nulls[col] = bank_nulls[col].astype('float')
#Cell 21
!pip install fancyimpute
from fancyimpute import IterativeImputer

# Assuming bank_nulls is your DataFrame with missing values
imputer = IterativeImputer()
bank_imputed = imputer.fit_transform(bank_nulls)

# Convert the imputed array back to a DataFrame
bank_imputed = pd.DataFrame(bank_imputed, columns=bank_nulls.columns)

# Display the descriptions
display(bank.describe(include='all').T, bank_imputed.describe(include='all').T)

#Cell 22
# Checking whether count of 0 in previous is equal to count of -1 in pdays
display(bank_imputed.loc[bank_imputed['previous'] == 0, 'previous'].value_counts().sum(),
        bank_imputed.loc[bank_imputed['pdays'] == -1, 'pdays'].value_counts().sum())
#Cell 23
img = sns.pairplot(bank_imputed[['age', 'education', 'default', 'balance', 'housing', 'loan', 'day', 'month',
                           'duration', 'campaign', 'pdays', 'previous', 'Target']], hue = 'Target')
#Cell 24
corr = bank_imputed.corr()

mask = np.zeros_like(corr, dtype=bool)
mask[np.triu_indices_from(mask)] = True

f, ax = plt.subplots(figsize=(11, 9))

cmap = sns.diverging_palette(220, 10, as_cmap=True)

sns.heatmap(corr, mask=mask, cmap=cmap, square=True, linewidths=.5, cbar_kws={"shrink": .5})
ax.set_title('Correlation Matrix of Data')
plt.show()
#Cell 25
# Filter for correlation value greater than 0.8 and less than 1
sort = corr.abs().unstack()
sort = sort.sort_values(kind = "quicksort", ascending = False)
sort[(sort > 0.8) & (sort < 1)]
#Cell 26
# Absolute correlation of independent variables with 'Target' i.e. the target variable
absCorrwithDep = []
allVars = bank_imputed.drop('Target', axis = 1).columns

for var in allVars:
    absCorrwithDep.append(abs(bank_imputed['Target'].corr(bank_imputed[var])))

display(pd.DataFrame([allVars, absCorrwithDep], index = ['Variable', 'Correlation']).T.\
        sort_values('Correlation', ascending = False))
#Cell 27
# Creating age groups
bank_imputed.loc[(bank_imputed['age'] < 30), 'age_group'] = 20
bank_imputed.loc[(bank_imputed['age'] >= 30) & (bank_imputed['age'] < 40), 'age_group'] = 30
bank_imputed.loc[(bank_imputed['age'] >= 40) & (bank_imputed['age'] < 50), 'age_group'] = 40
bank_imputed.loc[(bank_imputed['age'] >= 50) & (bank_imputed['age'] < 60), 'age_group'] = 50
bank_imputed.loc[(bank_imputed['age'] >= 60), 'age_group'] = 60
#Cell 28
# Check relationship between balance and age group by Target
fig = plt.figure(figsize = (15, 7.2))
ax = sns.boxplot(x = 'age_group', y = 'balance', hue = 'Target', palette = 'afmhot', data = bank_imputed)
ax.set_title('Relationship between balance and age group by Target')
#Cell 29
# Check relationship between campaign and age group by Target
fig = plt.figure(figsize = (15, 7.2))
ax = sns.boxplot(x = 'age_group', y = 'campaign', hue = 'Target', palette = 'afmhot', data = bank_imputed)
ax.set_title('Relationship between campaign and age group by Target')
#Baseline Model

#Cell 30

from sklearn.metrics import log_loss

# Separating dependent and independent variables
X = bank_imputed.drop(['Target'], axis = 1)
y = bank_imputed['Target']

# Splitting the data into training and test set in the ratio of 70:30 respectively
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)

dummy = DummyClassifier(strategy='most_frequent', random_state=random_state)
dummy.fit(X_train, y_train)
y_pred = dummy.predict(X_test)

accuracy_ = accuracy_score(y_test, y_pred)
pre_s = precision_score(y_test, y_pred, average='binary', pos_label=1)
re_s = recall_score(y_test, y_pred, average='binary', pos_label=1)
f1_s = f1_score(y_test, y_pred, average='binary', pos_label=1)


print('Training Score: ', dummy.score(X_train, y_train).round(3))
print('Test Score: ', dummy.score(X_test, y_test).round(3))

print('Accuracy: ', accuracy_.round(3))
print('Precision Score - Subscribe: ', pre_s.round(3))
print('Recall Score - Subscribe: ', re_s.round(3))
print('f1 Score - Subscribe: ', f1_s.round(3))


y_prob = dummy.predict_proba(X_test)[:, 1]
y_test_numerical = y_test.replace({'no': 0, 'yes': 1})
log_loss_val = log_loss(y_test_numerical, y_prob).round(3)
print('Log Loss:', log_loss_val)

df = pd.DataFrame([accuracy_.round(3), pre_s.round(3), re_s.round(3),
                   f1_s.round(3), log_loss_val], columns=['Baseline Model']).T
df.columns = ['Accuracy', 'Precision_Subscribe',
              'Recall_Subscribe', 'f1_Subscribe', 'Log_Loss']
df

#Cell 31
from sklearn.metrics import log_loss

def train_and_predict(n_splits, base_model, X, y, name, subscribe=1, oversampling=False):
    features = X.columns
    X = np.array(X)
    y = np.array(y)

    folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).split(X, y))

    train_pred = np.zeros((X.shape[0], len(base_model)))

    accuracy = []
    precision_subscribe = []
    recall_subscribe = []
    f1_subscribe = []
    log_loss_list = []

    for i, clf in enumerate(base_model):
        for j, (train, test) in enumerate(folds):

            # Creating train and test sets
            X_train = X[train]
            y_train = y[train]
            X_test = X[test]
            y_test = y[test]

            if oversampling:
                sm = SMOTE(random_state=random_state, sampling_strategy='minority')
                X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

                # fit the model
                clf.fit(X_train_res, y_train_res)

                # Get predictions
                y_true, y_pred = y_test, clf.predict(X_test)
                y_prob = clf.predict_proba(X_test)

                # Evaluate train and test scores
                train_ = clf.score(X_train_res, y_train_res)
                test_ = clf.score(X_test, y_test)

            else:
                # fit the model
                clf.fit(X_train, y_train)

                # Get predictions
                y_true, y_pred = y_test, clf.predict(X_test)
                y_prob = clf.predict_proba(X_test)

                # Evaluate train and test scores
                train_ = clf.score(X_train, y_train)
                test_ = clf.score(X_test, y_test)

            # Other scores
            accuracy_ = accuracy_score(y_true, y_pred).round(3)
            precision_b = precision_score(y_true, y_pred, average='binary', pos_label=subscribe).round(3)
            recall_b = recall_score(y_true, y_pred, average='binary', pos_label=subscribe).round(3)
            f1_b = f1_score(y_true, y_pred, average='binary', pos_label=subscribe).round(3)
            log_loss_val = log_loss(y_true, y_prob).round(3)

            # Appending scores
            accuracy.append(accuracy_)
            precision_subscribe.append(precision_b)
            recall_subscribe.append(recall_b)
            f1_subscribe.append(f1_b)
            log_loss_list.append(log_loss_val)

            print(f'Model- {name.capitalize()} and CV- {j}')
            print('-' * 20)
            print('Training Score: {0:.3f}'.format(train_))
            print('Test Score: {0:.3f}'.format(test_))
            print('Accuracy Score: {0:.3f}'.format(accuracy_))
            print('Precision Score - Subscribe: {0:.3f}'.format(precision_b))
            print('Recall Score - Subscribe: {0:.3f}'.format(recall_b))
            print('f1 Score - Subscribe: {0:.3f}'.format(f1_b))
            print('Log Loss: {0:.3f}'.format(log_loss_val))
            print('\n')

    # Creating a dataframe of scores outside the loop
    df = pd.DataFrame([np.mean(accuracy).round(3), np.mean(precision_subscribe).round(3),
                       np.mean(recall_subscribe).round(3),
                       np.mean(f1_subscribe).round(3),
                       np.mean(log_loss_list).round(3)], columns=[name]).T
    df.columns = ['Accuracy', 'Precision_Subscribe', 'Recall_Subscribe', 'f1_Subscribe', 'Log_Loss']

    return df

# Decision Tree Classifier
#Cell 32
# Decision Tree Classifier
dt_hyper = DecisionTreeClassifier(max_depth = 3, random_state = random_state)
base_model = [dt_hyper]
n_splits = 5
df1 = train_and_predict(n_splits, base_model, X, y, 'Decision Tree')
df = df._append(df1)
df
#Cell 33
dt_hyper = DecisionTreeClassifier(max_depth = 3, random_state = random_state)
dt_hyper.fit(X, y)
decisiontree = open('decisiontree.dot','w')
dot_data = export_graphviz(dt_hyper, out_file = 'decisiontree.dot', feature_names = X.columns,
    class_names = ['No', 'Yes'], rounded = True, proportion = False, filled = True)
decisiontree.close()

retCode = system('dot -Tpng decisiontree.dot -o decisiontree.png')
if(retCode>0):
    print('system command returning error: '+str(retCode))
else:
    display(Image('decisiontree.png'))
#Cell 34
print('Feature Importance for Decision Tree Classifier ', '--'*38)
feature_importances = pd.DataFrame(dt_hyper.feature_importances_, index = X.columns,
                                   columns=['Importance']).sort_values('Importance', ascending = True)
feature_importances.sort_values(by = 'Importance', ascending = True).plot(kind = 'bar', figsize = (15, 7.2))
#Bagging Classifier
#Cell 35
# Bagging Classifier
bgcl = BaggingClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3, random_state = random_state),
                         n_estimators = 50, random_state = random_state)
base_model = [bgcl]
n_splits = 5
df1 = train_and_predict(n_splits, base_model, X, y, 'Bagging ')
df = df._append(df1)
df
#Gradient Boosting Classifier
#Cell 36
# Gradient Boosting Classifier
gbcl = GradientBoostingClassifier(n_estimators = 50, random_state = random_state)
base_model = [gbcl]
n_splits = 5
df1 = train_and_predict(n_splits, base_model, X, y, 'Gradient Boosting ')
df = df._append(df1)
df
#Random Forest Classifier
#Cell 37
# Random Forest Classifier
rfc = RandomForestClassifier(n_jobs = -1, random_state = random_state)
base_model = [rfc]
n_splits = 5
df1 = train_and_predict(n_splits, base_model, X, y, 'Random Forest')
df = df._append(df1)
df
#Cell 38
rfc_over = RandomForestClassifier(bootstrap = True, class_weight = None, criterion = 'gini', max_depth = 3,
                                   max_features = 'auto', max_leaf_nodes = None, min_impurity_decrease = 0.0,
                                   min_samples_leaf = 1, min_samples_split = 2,
                                   min_weight_fraction_leaf = 0.0, n_estimators = 50, n_jobs = -1,
                                   oob_score = False, random_state = 42, verbose = 0, warm_start = False)
rfc_over.fit(X, y)

random_forest_tree = open('random_forest.dot','w')
dot_data = export_graphviz(rfc_over.estimators_[0], out_file = random_forest_tree, feature_names = list(X_train), class_names = ['No', 'Yes'], rounded = True, proportion = False, filled = True)
random_forest_tree.close()

retCode = system("dot -Tpng random_forest.dot -o random_forest.png")
if(retCode>0):
    print("system command returning error: "+str(retCode))
else:
    display(Image("random_forest.png"))
#Cell 39
print('Feature Importance for Random Forest Classifier ', '--'*38)
feature_importances = pd.DataFrame(rfc_over.feature_importances_, index = X.columns,
                                   columns=['Importance']).sort_values('Importance', ascending = True)
feature_importances.sort_values(by = 'Importance', ascending = True).plot(kind = 'bar', figsize = (15, 7.2))
#Cell 40
if df.index.duplicated().any():
  df = df.loc[~df.index.duplicated(), :]
if df.columns.duplicated().any():
  df = df.loc[:, ~df.columns.duplicated()]
print('Conditional Formatting on the scores dataframe ', '--'*39)
display(df.style.background_gradient(cmap = sns.light_palette('green', as_cmap = True)))

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import HTML

# Assuming df is your DataFrame containing the results
if df.index.duplicated().any():
    df = df.loc[~df.index.duplicated(), :]
if df.columns.duplicated().any():
    df = df.loc[:, ~df.columns.duplicated()]

# Exclude the Baseline Model from the DataFrame
df_without_baseline = df.drop('Baseline Model', axis=0)

# Display the table with conditional formatting
print('Conditional Formatting on the scores dataframe ', '--'*39)
display(df_without_baseline.style.background_gradient(cmap = sns.light_palette('green', as_cmap = True)))

# Plotting the DataFrame
plt.figure(figsize=(10, 6))
sns.heatmap(df_without_baseline, annot=True, cmap='YlGnBu', fmt='.3f', cbar=False)
plt.title('Conditional Formatting on the scores dataframe')
plt.tight_layout()
plt.savefig('results_table.png')

# Display the image
plt.show()

#Cell 41

print(df.columns)

##Modal Accuracy Comparison
#Cell 42

# Exclude 'Baseline Model' from the dataframe before plotting
df_no_baseline = df.drop(index='Baseline Model')

# Setting up the bar width and positions
barWidth = 0.15
r1 = np.arange(len(df_no_baseline))

# Make the plot for Accuracy
fig = plt.figure(figsize=(15, 7.2))
ax = fig.add_subplot(111)

bars1 = ax.bar(r1, df_no_baseline['Accuracy'], color='lightblue', width=barWidth, edgecolor='grey', label='Accuracy', zorder=3)

ax.set_ylim(0, 1.0)

# Add xticks on the middle of the group bars
#ax.set_xlabel('Model', fontweight='bold')
ax.set_xticks(r1)
ax.set_xticklabels(df_no_baseline.index, rotation=90)

# Create legend
plt.legend()

plt.title('Model Accuracy Comparison')

# Add values on top of each bar
def add_values_on_top(bars):
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height, round(height, 3), ha='center', va='bottom')

add_values_on_top(bars1)

plt.show()

#Cell 43

# Exclude 'Baseline Model' from the dataframe before plotting
df_no_baseline = df.drop(index='Baseline Model')

# Setting up the bar width and positions
barWidth = 0.15
r2 = np.arange(len(df_no_baseline))

# Make the plot for Precision
fig = plt.figure(figsize=(15, 7.2))
ax = fig.add_subplot(111)

bars2 = ax.bar(r2, df_no_baseline['Precision_Subscribe'], color='lightyellow', width=barWidth, edgecolor='grey', label='Precision', zorder=3)

ax.set_ylim(0, 1.0)

# Add xticks on the middle of the group bars
#ax.set_xlabel('Model', fontweight='bold')
ax.set_xticks(r2)
ax.set_xticklabels(df_no_baseline.index, rotation=90)

# Create legend
plt.legend()

plt.title('Model Precision Comparison')

# Add values on top of each bar
def add_values_on_top(bars):
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height, round(height, 3), ha='center', va='bottom')

add_values_on_top(bars2)

plt.show()

#Cell 44

# Exclude 'Baseline Model' from the dataframe before plotting
df_no_baseline = df.drop(index='Baseline Model')

# Setting up the bar width and positions
barWidth = 0.15
r3 = np.arange(len(df_no_baseline))

# Make the plot for Log Loss
fig = plt.figure(figsize=(15, 7.2))
ax = fig.add_subplot(111)

bars3 = ax.bar(r3, df_no_baseline['Log_Loss'], color='lightcoral', width=barWidth, edgecolor='grey', label='Log Loss', zorder=3)

ax.set_ylim(0, 1.0)

# Add xticks on the middle of the group bars
ax.set_xlabel('Model', fontweight='bold')
ax.set_xticks(r3)
ax.set_xticklabels(df_no_baseline.index, rotation=90)

# Create legend
plt.legend()

plt.title('Model Log Loss Comparison')

# Add values on top of each bar
def add_values_on_top(bars):
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height, round(height, 3), ha='center', va='bottom')

add_values_on_top(bars3)

plt.show()

#Cell 45

# Exclude 'Baseline Model' from the dataframe before plotting
df_no_baseline = df.drop(index='Baseline Model')

barWidth = 0.15
r1 = np.arange(len(df_no_baseline))
r2 = [x + barWidth for x in r1]
r3 = [x + barWidth for x in r2]
r4 = [x + barWidth for x in r3]

# Make the plot
fig = plt.figure(figsize=(15, 7.2))
ax = fig.add_subplot(111)

bars1 = ax.bar(r1, df_no_baseline['Accuracy'], color='lightblue', width=barWidth, edgecolor='grey', label='Accuracy', zorder=3)
bars2 = ax.bar(r2, df_no_baseline['Precision_Subscribe'], color='lightyellow', width=barWidth, edgecolor='grey', label='Precision', zorder=2)
bars3 = ax.bar(r3, df_no_baseline['Log_Loss'], color='lightcoral', width=barWidth, edgecolor='grey', label='Log Loss', zorder=1)

ax.set_ylim(0, 1.0)

# Add xticks on the middle of the group bars
ax.set_xlabel('Model', fontweight='bold')
ax.set_xticks([r + barWidth * 1.5 for r in range(len(df_no_baseline))])
ax.set_xticklabels(df_no_baseline.index, rotation=90)

# Create legend without the 'Baseline Model' label
plt.legend()

plt.title('Model Scores Comparison')

# Add values on top of each bar
def add_values_on_top(bars):
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height, round(height, 3), ha='center', va='bottom')

add_values_on_top(bars1)
add_values_on_top(bars2)
add_values_on_top(bars3)

plt.show()

